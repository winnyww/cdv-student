Response to Reading 2

When I was in New York last year, I took a class at Tandon called Disability Studies where the students would share the classroom with local residents with impairments/disabilities. We learned about the bias in auto-driving vehicles. In the auto-driving system, an algorithm is used to detect humans and things in the trajectories of driving so the vehicles would react by going forward or stop immediately. The problem is that very limited data of disabled people is used to train the machine, which results in potential dangerous accidents such as reading someone in a wheelchair as an object thus the vehicle wouldn't slow down. This is a similar example of algorithm bias as Joy Buolamwini introduced.

As mentioned in the podcasts by Virginia Eubanks and Kate Crawford, it is terrifying that people more or less wish the machine/AI can be more objective, or neutral. Taking the social welfare system as an example, evidence-based technologies are "supposed to be more objective" to decide who is more deserving by fairing out patterns of discriminating decision-making. However, Eubanks believes despite the good objective, the realistic outcome is a myth. It ended up diverting people from gaining their entitlements, and such uses of technologies had become nothing but an objective-appearing shield for certain political strategy by saying "it's the machine deciding so don't blame the human" (this is my rephrase).

It is very interesting to see the construction of some type of authority in the machines, especially in the Chinese society. Such authority had existed in the emperor's words, the government's rules, the elderly's persuasion and now the algorithm taking the jobs of the police and the manager. Each time, people don't want to question the legitimacy of the authority, and all of them represent some kind of objective agenda, such as "it is for the greater good" or "I'm thinking for your own benefit". It is because the emperor's the best and wisest, the government is the official and fairest, elderlies have the most experience and the machines are the fastest and most "objective" as they are made of 1s and 0s. I witnessed an "empathy-overwrite" because of the coronavirus health code just last year. On the basis of a really strict travel restriction rules, all citizens (Chinese or not) won't be able to board their abnormally expensive flights unless their international health code is green. To do it, you need to fill in a self-report of personal information, health declaration and daily temperature for 14 continual days prior to departure making no mistakes. Sometime in summer 2020, two Chinese elderlies were denied to board their $15000-worth flights in LA because they made one typo mistake just one day before. The two poor citizens cried aloud and kneeled down in front of the flight crew in the airport but no one could help them.

Because the health code was created to provide an objective insight to each passenger's health condition for the greater good; if you could just make no mistakes like the machine, why should anyone or anything deny your boarding? Moreover, no one could overwrite the decision made by the machine. We can only let ourselves be overwritten at the price of the loss of empathy.
